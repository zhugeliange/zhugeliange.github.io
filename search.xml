<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[redux-toolkit知识点]]></title>
    <url>%2Fpost%2Fredux-toolkit%E7%9F%A5%E8%AF%86%E7%82%B9%20%2F</url>
    <content type="text"><![CDATA[首先理解redux所谓 Redux，就是将动作(action) 变换成 state 转换函数(reducer)，然后放到一个统一的地方(store)来 setState 而已。特性有3个：单向性：单向数据流其实并不是redux的特性，而是react本身的思想。这个下面有例子会说明。唯一性：指的是应用的数据都会集中存储在一个地方，这个数据Store就像一个池子，任何组件都可以通过固定的管道来传输或者获取这个池子里面的数据时间旅行：这个“时间旅行”另外的意思是可预测（predictable），即容易理解的代码。在redux里，任何一个数据都有状态。一个用户操作或者程序需要去修改数据，都必须触发Action，这时在redux看来，其实数据是从一个状态，变化成另一个状态。这么一来，数据就变得可预测，可以知道数据的前置状态(prev state)和后置状态(next state)分别是什么，如果在这里加上单元测试，也是极其容易的一件事情。这意味着你必须遵循一定的规则才可以让你的程序走通。所以实现一个功能通常的得相应的创建三个文件：Action，Reducer，Store，同时也是Redux最重要的3个概念。当然有了redux-toolkit之后这些都可以简化了，这个后面说。Action：一言蔽之就是指的用户的一个行为，例如，click，hover，input等。并通过Dispatch将这个行为通知给Store。Reducer：Store内部有很多个Reducer，用来接收Action，并将Store的某些State做相应的更新，同时出发View的更新。Store：作为一个总的容器来管理以上发生的行为及相关的数据。开始使用redux-toolkitredux的毛病就是配置太过繁琐，有大量的冗余，且对异步请求支持不是很好。redux-toolkit实际上就是一些redux相关的工具集：configureStore(): 包装 createStore 以提供简化的配置选项和良好的默认预设。它可以自动组合你的切片 reducers，添加您提供的任何 Redux 中间件，默认情况下包含 redux-thunk ，并允许使用 Redux DevTools 扩展。createReducer(): 为 case reducer 函数提供 action 类型的查找表，而不是编写switch语句。此外，它会自动使用immer库来让您使用普通的可变代码编写更简单的 immutable 更新，例如 state.todos [3] .completed = true 。createAction(): 为给定的 action type string 生成一个 action creator 函数。函数本身定义了 toString()，因此它可以用来代替 type 常量。createSlice(): 接受一个 reducer 函数的对象、分片名称和初始状态值，并且自动生成具有相应 action creators 和 action 类型的分片reducer。createAsyncThunk: 接受一个 action type string 和一个返回 promise 的函数，并生成一个发起基于该 promise 的pending/fulfilled/rejected action 类型的 thunk。createEntityAdapter: 生成一组可重用的 reducers 和 selectors，以管理存储中的规范化数据createSelector 组件 来自 Reselect 库，为了易用再导出。除此之外，新版redux-toolkit还提供了RTK-query用来专门处理异步请求。比fetch，axios，react query方案都更好，具体好在哪里，请自行谷歌～按我个人经验，分享一个使用redux-toolkit的最佳实践：在入口文件app.tsx引入Provider组件并放在最外层，加一个store属性，值可以单独写一个store.ts配置文件来引入。在store.ts配置文件里面用configureStore方法做全局状态的唯一容器，然后export出去。创建一个rootReducer.ts文件，然后里面用combineReducers方法组合所有的reducer，然后export出去交给store.ts来管理。然后就是根据项目的特性依次创建相应的Slice切片，如果是本地状态，就用createSlice方法集成state，reducer。如果是异步的请求，可以用createAsyncThunk也可以RTK-query来处理，个人推荐后者。如果是react16之后的版本使用hook方式的话还可以将useSelect方法和useDispatch做个简单的封装，以供全局使用。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>react</tag>
        <tag>redux</tag>
        <tag>redux-toolkit</tag>
        <tag>RTK-query</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ant-design知识点]]></title>
    <url>%2Fpost%2Fant-desgin%E7%9F%A5%E8%AF%86%E7%82%B9%2F</url>
    <content type="text"><![CDATA[坑～如果在ant-desgin-pro项目里面引入ant-desgin组件报错的话，可以把src/.umi文件夹下的内容删掉再重新start就好了。这个坑据官方说法是因为热更新的一个bug。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>知识点</tag>
        <tag>框架</tag>
        <tag>ant-design</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[前端项目实现跨域的几种方式]]></title>
    <url>%2Fpost%2F%E5%89%8D%E7%AB%AF%E9%A1%B9%E7%9B%AE%E5%AE%9E%E7%8E%B0%E8%B7%A8%E5%9F%9F%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F%20%2F</url>
    <content type="text"><![CDATA[啥叫跨域请自行谷歌～jsonp原理大概就是，虽然图片这些静态资源不能跨域，但是js可以啊，于是就在目标页面回调本地页面的方法,并带入参数，这就实现了最简单的跨域。例如：jquery的ajax方法里就支持jsonp。1234567891011121314 $.ajax({ url: "http://localhost:8080/api/jsonp", dataType: "jsonp", // 选择jsonp类型 type: "get", data: { id: 1 }, jsonp: "cb", success: function (data) { console.log(data); } });直接在package-json文件里配置proxy上面jsonp方式太老了，对于现代化的诸如react/vue这一类支持node,webpack的框架，可以直接在package-json文件里配置proxy的值，这个值就是你要跨域的目标地址。例如：12345{ ... "proxy": "http://localhost:8000", ...}通过http-proxy-middlware库上面的package-json方式虽然很简单，但是不支持多个跨域，而且部署到生产环境也不稳定。还可以用npm装个http-proxy-middlware库，这是个专门用来代理url请求的中间件，很多框架实际上也都是基于这个库的（例如：蚂蚁的umi配置里的proxy选项）。示例：1234567import * as express from 'express';import { createProxyMiddleware, Filter, Options, RequestHandler } from 'http-proxy-middleware';const app = express();app.use('/api', createProxyMiddleware({ target: 'http://www.example.org', changeOrigin: true }));app.listen(3000);利用nginx的反向代理nginx是啥？请自行谷歌～如果搞过php应该对这个很熟，例如本人。方案就是在您想的配置文件里面，配一个反向代理，将前端访问api的地址指向真正的后端api地址，例如：1234location /api/ # 一般以这种形式做api的标记，也可以自定义其他的{ proxy_pass http://api.xxx.com/; // 这个就是真实的后端目标api地址。}这几种方案怎么选型，按照我的经验来看，如果是jquery这种老项目，就用它封装好的jsonp方法就好了。如果是react这种新式的框架，本地开发直接在package-json里面配个proxy就行了，简单粗暴，线上生产环境如果后端是用的node技术栈（例如：express）可以用http-proxy-middlware，这是标准适配。其他的都可以选用最后一种nginx方式，这种配置也很简单，而且几乎没有任何限制，唯一要求的就是对nginx稍微有点了解吧。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>跨域</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[react-router知识点]]></title>
    <url>%2Fpost%2Freact-router%E7%9F%A5%E8%AF%86%E7%82%B9%2F</url>
    <content type="text"><![CDATA[坑～如果要用react-router的方法，那么必须在\组件内部（一般会放在入口app.tsx文件里）。否则根本不生效，除非把history对象从顶层通过props的方式传到要使用的组件，如果层级太多可以考虑用context方式。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>知识点</tag>
        <tag>react</tag>
        <tag>react-router</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[react知识点]]></title>
    <url>%2Fpost%2Freact%E7%9F%A5%E8%AF%86%E7%82%B9%2F</url>
    <content type="text"><![CDATA[jsx里自定义的组件必须以大写字母开头，原生组件以小写字母开头，且可以使用属性语法，例如：只存最原始的状态，凡是需要计算得到的值都不建议单独存储，而是通过计算得到。组件尽量无状态，所有的数据通过props获取。react router分为三种形式：普通url模式，hash模式（多个#，用于兼容旧版本浏览器），内存模式（类似于存储在state中，url中不显示）。react router常用api：：普通链接，但是不会触发浏览器的刷新。：类似于Link，但是多了个选中状态。：满足条件时提示用户是否离开当前页面。：页面重定向跳转，例如登录判断。：最基本的路由，根据路径匹配显示相应的页面或组件。：多个Route的匹配规则都满足时，默认会都显示，如果只想显示第一个，可以用Switch将多个Route包起来。next.js适合重度依赖ssr的首页性能优先项目，其他情况下create react app都可以满足日常需求。webpack是先编译打包，然后再启动服务器，而vite是先启动服务器，然后按需加载编译资源。开发构建vite优先，因为性能更好，生产构建webpack优先，因为功能更加齐全。redux原理：用户更改view触发一个action，dispatch接收这个action交给相应的reducer，reducer更新相应的store，从而触发ui的更新。因为render最外层只能有一个标签，所以如果有多个标签时，可以用标签包起来。标签只有key可选属性，适合遍历时指定。也可以用的形式，但是没有key属性。React.lazy函数用来动态import组件，即用到的时候才加载，配合Suspense可以实现，等待加载未完成时显示相应的loading效果。错误边界组件，可以捕获并打印发生在其子组件树任何位置的JavaScript错误，并且会渲染出备用UI。适合用来处理React组件内部崩溃引发的界面白屏等错误（正常的请求报错或者页面事件抛出异常等错误不算）。当多个不同层级的组件之间需要共享状态时，依次逐层通过props来传递state会使得代码太过冗余。可以使用context，比如说当前认证的用户、主题或首选语言等。不过context会造成一定性能的损耗，替代方案可以将整个子组件直接传入props来传递state。当处理一些原生组件或者第三方组件时，需要直接操作dom，可以使用ref来直接访问原生dom。组件是将props转换为ui，而高阶组件是将组件转换为另一个组件，即高阶组件的props参数是组件。Portals可以将子节点渲染到父节点之外，并且保持和普通子结点相对于父节点一致的行为。适合model弹框之类的场景。React组件生命周期：挂载时：constructor -> render -> React更新dom和refs -> componentDidMount更新时：constructor -> render(New props()/setState()/forceUpdate()) -> React更新dom和refs -> componentDidUpdate卸载时：componentWillUnmount]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>知识点</tag>
        <tag>react</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[typescript知识点]]></title>
    <url>%2Fpost%2FtypeScript%E7%9F%A5%E8%AF%86%E7%82%B9%2F</url>
    <content type="text"><![CDATA[数组array类型只能为一种。1234// 这三种声明数组的方式等价let a : number[] = [1,2];let b : Array = [1,2];let c = [1,2]; // 隐式声明元组tuple类型可以有多种，固定长度固定类型，声明时需要显式指定类型，不然就只是联合类型。12let a = [1,'2']; // 这种隐式声明并不是元组tuple，而是联合类型(number | string)[]，隐式声明默认取最小能包含变量的类型范围let b : any[] = [1,'2']; // 这个是元组tuple，因为可以包含任意类型的元素直接对元组类型的变量进行初始化或者赋值的时候，需要提供所有元组类型中指定的项，且元素与声明的类型一一对应。123let a : [number,string];a = [1,2]; // 元素类型应该和声明的一一对应a = [1,'b']; // 正确元组虽然固定长度，但是也可以越界添加元素，不过添加的元素类型为声明时的联合类型。12345let a : [number,string];a = [1,'b'];a.push('c');a.push(2);a.push(true); // 错误，因为声明时只有number和string类型联合类型union既可以指定多个类型也可以指定多个确定的值，这也就是字面量类型literal。12let a : number | string; // 联合类型，值可以为数字或者字符串let b : 1 | '2' | true | [1,2]; // 值只能为1，'2'，true，[1,2]枚举类型enum的值默认为索引数字，后面依次+1，也可以手动指定值，类型为数字或者字符串，如果是被赋值为字符串，则其后面的元素必须再次手动赋值，直到为数字为止其内部是一组类似于数组的键值对，如果值为数字类型还会默认添加一组键值对互换的值，所以可以按照数组的方式来访问。且元素为只读属性，不可以再另外赋值。可以包含计算元素，但是其后面不能使用值默认的自动推断，必须手动复赋值。123456789101112131415161718192021222324252627enum a { // 声明时前面不用加let red, // 值为0 green, // 值为1 blue // 值为2}// 完整值为 { '0': 'red', '1': 'green', '2': 'blue', red: 0, green: 1, blue: 2 }，所以a.red或者a['red']为0，a[0]或者a['0']为redenum b { red, // 值为0 green = 2, // 值为2 blue // 值为3}// 完整值为 { '0': 'red', '2': 'green', '3': 'blue', red: 0, green: 2, blue: 3 }，所以b.green或者b['green']为2，b[2]或者b['2']为greenenum c { red, // 值为0 green = 'hehe', // 值为hehe blue = 6 // 必须再次手动赋值}// 完整值为 { '0': 'red', '6': 'blue', red: 0, green: 'hehe', blue: 6 }，所以c.green或者c['green']为hehe，c[6]或者c['6']为blueenum d { red, green = 'green'.length, blue = 2 // 这里必须手动赋值，因为不确定上一个元素的值}常数枚举使用const enum定义，与普通枚举的区别是，它会在编译阶段被删除，在编译生成的js中直接使用元素的值，并且不能包含计算成员。12345678910const enum Directions { Up, Down, Left, Right}let directions = [Directions.Up, Directions.Down, Directions.Left, Directions.Right];// 编译结果是var directions = [0 /* Up */, 1 /* Down */, 2 /* Left */, 3 /* Right */];外部枚举使用declare enum定义，与普通枚举的区别是，它只会用于编译时的检查，编译生成的js文件中会被删除，所以常用在声明文件里面用来做类型检查。unknown类型是any类型的安全版本，因为需要更多的类型断言，unknown类型是所有类型的顶层类型，但是还保留了类型检查，而any类型既是所有类型的顶层类型同时也放弃了类型检查，原则上优先使用unknown类型。void类型表示不存在，例如函数没有返回值，而undefined类型则表示没有值，例如变量声明了但是没有赋值。never类型表示函数永远不会执行完，例如抛出异常或者死循环。类型断言type assertions，表示手动指定变量的类型。强制转换指的是改变类型，而类型断言则指的是指定某些个大类型之中的小类型，比如any中的number。1234567891011121314let a : any; a = 1;let b = (a)++; // 值为2，将any类型断言为number类型，但是这种尖括号方式在react中可能会引起歧义，所以改用下面的方式let c = (a as number)++; // 值为3let a : any; a = 1;let b = (a) + '1'; // 值为11let c = (a as number | string) + '1'; // 值为11let a : any; a = '1';let b = (a).length; // 值为1let c = (a as string).length; // 值为1函数的可选参数或者默认参数都要放在末尾。0x开头表示二进制，0b开头表示八进制。可以使用null和undefined来定义这两个原始数据类型。12let u: undefined = undefined;let n: null = null;undefined和null是所有类型的子类型，可以赋值给其他类型的变量。而void类型的变量不可以，且只能赋值为undefined，虽然这样并没有意义。12345678// 这样不会报错let a: number = undefined;// 这样也不会报错let a: undefined;let b: number = a;// void类型的变量不可以let a: void;let b: number = a;类型别名用来给一个类型起个新名字，常用于联合类型。123456789101112131415161718type a = string;type b = () => string;type c = a | b;function getName(d: c): a { if (typeof d === 'string') { return d; } else { return d(); }}let haha = (e : string) : string => { return e;}getName('hehe'); // 输出hehegetName(haha('haha')); // 输出haha修饰符和readonly还可以使用在构造函数参数中，等同于类中定义该属性同时给该属性赋值，使代码更简洁。1234567891011class A { public constructor(public a: string) { }}// 等同于class A { public a: string; constructor(a) { this.a = a; }}readonly只允许出现在属性声明或索引签名或构造函数中，如果和其他访问修饰符同时存在的话，需要写在其后面。1234567891011class A { readonly a: string; constructor(a) { this.a = a; }}class B { constructor(public readonly b) { }}]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>知识点</tag>
        <tag>前端</tag>
        <tag>typescript</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[目前最好的白嫖图床方案]]></title>
    <url>%2Fpost%2F%E7%9B%AE%E5%89%8D%E6%9C%80%E5%A5%BD%E7%9A%84%E7%99%BD%E5%AB%96%E5%9B%BE%E5%BA%8A%E6%96%B9%E6%A1%88%2F</url>
    <content type="text"><![CDATA[废话不多说直接给结论：方案一：GitHub+PicGo+jsDelivrGitHub作为图片存储仓库PicGo做图片上传工具，新版PicGo支持Typora，以后写markdown博客再也不用担心图片往哪放啦～jsDelivr做cdn加速，老牌厂商，最主要是完全免费！另外PicGo也可以换成PicX，效果差不多，看个人喜好吧。方案二：直接用七牛云存储这个方案最大的好处是适合集成在开发代码里，七牛作为国内老牌云服务厂商，本人也是用了很多年，基本上常用场景的API都有提供，且各大语言的sdk基本上都支持，且文档详细，有问题回复效率也挺高的。而且还是那一点，不要钱！当然这里指的是每个用户都有一定的免费额度，以我个人多年的使用经验来看，个人项目免费额度完全够用。但是！现在七牛有一个不好的地方，就是创建存储空间的时候需要一个已经备案自己的域名。虽然每次会送一个月时间的测试域名，但是到期后里面村的图片都挂了。。。所以如果没有已备案的域名还是老老实实用第一个方案吧。方案三：其他公共的图床这些实际上就是很多了，但是想想你放心把自己的私人或者公司项目图片放在公共服务器上嘛？指不定哪天就挂了，要是本地还没有备份，那一张一张的重新做图，酸爽不言而喻了吧～]]></content>
      <categories>
        <category>工具</category>
      </categories>
      <tags>
        <tag>图床</tag>
        <tag>白嫖</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[es6知识点]]></title>
    <url>%2Fpost%2Fes6%E7%9F%A5%E8%AF%86%E7%82%B9%2F</url>
    <content type="text"><![CDATA[const实际上保证的，并不是变量的值不得改动，而是变量指向的那个内存地址所保存的数据不得改动。对于简单类型的数据（数值、字符串、布尔值），值就保存在变量指向的那个内存地址，因此等同于常量。但对于复合类型的数据（主要是对象和数组），变量指向的内存地址，保存的只是一个指向实际数据的指针，const只能保证这个指针是固定的（即总是指向另一个固定的地址），至于它指向的数据结构是不是可变的，就完全不能控制了。因此，将一个对象声明为常量必须非常小心。123const a = {};a.prop = 1; // 为a添加一个属性，可以成功foo = {}; // 将a指向另一个对象，就会报错如果解构赋值的默认值是一个表达式，那么这个表达式是惰性求值的，即只有在用到的时候，才会求值。12345function b() { console.log('b');}let [a = b()] = [1]; // 因为a能取到值1，所以函数b根本不会执行。解构赋值的默认值可以引用解构赋值的其他变量，但该变量必须已经声明。123let [a = 1, b = a] = []; // a=1; b=1let [a = 1, b = a] = [1, 2]; // a=1; b=2let [a = b, b = 1] = []; // 报错，因为b还没有声明就被赋值给了a数组和对象都可以解构赋值，不过对象的解构赋值不是按照顺序一一对应，而是按照key来对应的。Number.isFinite()用来检查一个数值是否为有限的（finite），即不是Infinity。如果参数类型不是数值，律返回false。123456Number.isFinite(15); // trueNumber.isFinite(NaN); // falseNumber.isFinite(Infinity); // falseNumber.isFinite(-Infinity); // falseNumber.isFinite('foo'); // falseNumber.isFinite(true); // falseNumber.isNaN()用来检查一个值是否为NaN。如果参数类型不是NaN，一律返回false。1234567Number.isNaN(NaN) // trueNumber.isNaN(9/NaN) // trueNumber.isNaN('true' / 0) // trueNumber.isNaN('true' / 'true') // trueNumber.isNaN(15) // falseNumber.isNaN('15') // falseNumber.isNaN(true) // false函数的递归可能会造成内存溢出，影响性能，可以用尾调用来优化，即最后一步调用。Array.from方法用于将类似数组的对象（array-like object）和可遍历（iterable）的对象（包括 ES6 新增的数据结构 Set 和 Map），转为真正的数组。Array.of()方法用于将一组值，转换为数组。这个方法的主要目的，是弥补数组构造函数Array()的不足。因为参数个数的不同，会导致Array()的行为有差异。123456789Array() // []Array(3) // [, , ,] 参数只有一个正整数时，实际上是指定数组的长度Array(3, 11, 8) // [3, 11, 8]// Array.of()基本上可以用来替代Array()或new Array()，并且不存在由于参数不同而导致的重载Array.of() // []Array.of(undefined) // [undefined]Array.of(1) // [1]Array.of(1, 2) // [1, 2]数组实例的find方法，用于找出第一个符合条件的数组成员。它的参数是一个回调函数，所有数组成员依次执行该回调函数，直到找出第一个返回值为true的成员，然后返回该成员。如果没有符合条件的成员，则返回undefined。find方法的回调函数可以接受三个参数，依次为当前的值、当前的位置和原数组。支持NaN的判断。123[1, 5, 10, 15].find(function(value, index, arr) { return value > 9;}) // 10数组实例的findIndex方法的用法与find方法非常类似，返回第一个符合条件的数组成员的位置，如果所有成员都不符合条件，则返回-1。findIndex方法的回调函数可以接受三个参数，依次为当前的值、当前的位置和原数组。支持NaN的判断。123[1, 5, 10, 15].findIndex(function(value, index, arr) { return value > 9;}) // 2keys()是对键名的遍历、values()是对键值的遍历，entries()是对键值对的遍历。includes方法返回一个布尔值，表示某个数组是否包含给定的值，与字符串的includes方法类似。一共两个参数，第一个参数表示目标值，第二个参数表示搜索的起始位置，默认为0。如果第二个参数为负数，则表示倒数的位置，如果这时它大于数组长度，则会重置为从0开始。支持NaN的判断，可以用来替换indexOf。类似的有Map结构的has方法，是用来查找键名的。Set结构的has方法，是用来查找值的。12[1, 2, 3].includes(3, 3); // false[1, 2, 3].includes(3, -1); // trueflat()方法会将数组‘拉平’为一维数组，且 不改变原数组。默认只‘拉平’一层，要想多层可以传参数指定，参数为Infinity表示不管原数组多少层，全部变为一维数组。允许在大括号里面，直接写入变量和函数，作为对象的属性和方法，除了属性简写，方法也可以简写。12345678910111213141516171819202122232425262728const c = {a: b}; // 等同于 const a = 'b';const c = {a};function f(x, y) { return {x, y};}// 等同于function f(x, y) { return {x: x, y: y};}f(1, 2) // Object {x: 1, y: 2}const o = { method() { return "Hello!"; }};// 等同于const o = { method: function() { return "Hello!"; }};fromEntries()方法是entries()方法的逆操作，用于将一个键值对数组转为对象。常用来配合URLSearchParams对象，将查询字符串转为对象。1Object.fromEntries(new URLSearchParams('foo=bar&baz=qux')); // { foo: "bar", baz: "qux" }assign()方法用于对象的合并，将源对象（source）的所有可枚举属性，复制到目标对象（target）。对于数组也会当作对象来处理，所以属性肯定会重复。如果属性名相同则后面的替换前面的。set结构，元素不能重复，内部严格比较，例如1和‘1’不相等，用new Set()来生成。12345// 去除数组中的重复元素[...new Set([1,2,1])] // [1,2]// 去除字符串的重复字符[...new Set('ababbc')].join('') // ‘abc’set结构有size属性表示元素个数，add方法添加元素（重复的元素会自动忽略），delete方法删除元素，has方法查找元素是否存在，clear方法清除所有元素。12345a = new Set([1,2]);a.add(3); // [1,2,3]a.delete(2); // [1,3]a.has(1); // truea.clear();set结构的遍历方法：keys方法遍历所有的键名，values方法遍历所有的值，entries方法遍历所有的键值对，forEach使用回调函数遍历每个成员。set结构的键名就是键值，所以keys方法和values方法等价。map结构使用new Map()来生成，传统的object对象结构的键名只能是字符串，而map结构的键名可以是任意类型，所以键值对的hash类型更推荐用map。结构有size属性表示元素个数，set方法添加元素（键名重复则会替换），get方法根据键名获取值（键名找不到则返回undefined），has方法查找值（参数为值不是键名）是否存在，delete方法根据键名删除元素，clear方法清除所有元素。12345678910a = new Map([ ['a','b'], ['c',2], [1,'d'],]);a.set(2,'e'); // Map { 'a' => 'b', 'c' => 2, 1 => 'd', 2 => 'e' }a.get(2); // 'e'a.has(2); // truea.delete(2); // Map { 'a' => 'b', 'c' => 2, 1 => 'd' }a.clear(); // Map {}map结构的遍历方法：keys方法遍历所有的键名，values方法遍历所有的值，entries方法遍历所有的键值对，forEach使用回调函数遍历每个成员。map结构与其他结构的互相转换：1234567891011121314151617181920212223242526272829a = new Map([ ['a','b'], ['c',2], [1,'d'],]);// map转换为数组，使用扩展运算符或者Array.from()方法let b = [...a]; // [ [ 'a', 'b' ], [ 'c', 2 ], [ 1, 'd' ] ]let c = Array.from(a); // [ [ 'a', 'b' ], [ 'c', 2 ], [ 1, 'd' ] ]// 数组转换为map，直接当成参数传入new Map()方法即可let d = new Map(c); // Map { 'a' => 'b', 'c' => 2, 1 => 'd' }// map转换为对象，如果map的所有键都是字符串，则可以无损地转为对象。如果有非字符串的键名，那么这个键名会被转成字符串，再作为对象的键名。let e = new Object();d.forEach((v,k)=>{ e[k] = v;});// 对象转换为map，通过Object.entries()方法let f = new Map(Object.entries(e)); // Map { '1' => 'd', 'a' => 'b', 'c' => 2 }// map转换为json，分为两种：如果map的键名全部都是字符串则可以转换为json对象（即先用JSON.stringify()方法转换成对象再转换成json），否则转换为json数组（即先用JSON.stringify()方法转换成数组再转换成json）。let g = JSON.stringify(e); // {"1":"d","a":"b","c":2}let h = JSON.stringify(b); // [["a","b"],["c",2],[1,"d"]]// json转换为map，分为两种：如果是键名全部都是字符串的json对象可以先用JSON.parse()方法转换成对象再用Object.entries()方法遍历，最后用new Map()方法生成map；否则键名不为字符串，或者多层数组或对象嵌套的json数组可以先用JSON.parse()方法转换成数组，再用new map()方法生成。let i = new Map(Object.entries(JSON.parse(g))); // Map { '1' => 'd', 'a' => 'b', 'c' => 2 }let j = new Map(JSON.parse(h)); // Map { 'a' => 'b', 'c' => 2, 1 => 'd' }Promise是异步编程的一种解决方案，用new Promise()方法来生成。Promise对象的状态不受外界影响。Promise对象代表一个异步操作，有三种状态：pending（进行中）、fulfilled（已成功）和rejected（已失败）。只有异步操作的结果，可以决定当前是哪一种状态，任何其他操作都无法改变这个状态。Promise对象一旦状态改变，就不会再变，任何时候都可以得到这个结果。Promise对象的状态改变，只有两种可能：从pending变为fulfilled和从pending变为rejected。只要这两种情况发生，状态就凝固了，不会再变了，会一直保持这个结果，这时就称为 resolved（已定型）。如果改变已经发生了，你再对Promise对象添加回调函数，也会立即得到这个结果。这与事件（Event）完全不同，事件的特点是，如果你错过了它，再去监听，是得不到结果的。Promise也有一些缺点。首先，无法取消Promise，一旦新建它就会立即执行，无法中途取消。其次，如果不设置回调函数，Promise内部抛出的错误，不会反应到外部。第三，当处于pending状态时，无法得知目前进展到哪一个阶段（刚刚开始还是即将完成）。Promise对象有then(方法表示状态改变时的回调函数。有两个可选参数参数，第一个参数为状态成功时的回调函数，第二个参数为状态失败时的回调函数。Promise对象也有catch()方法和finally()方法来表示捕获异常和最终执行。Generator函数是分段执行的，每次手动调用next()方法执行时，碰到函数内部的yield定义的状态就会停止，等到下次执行时再从上次停止的地方接着执行，是一种异步函数。Generator函数与两个特征：一是，function关键字与函数名之间有一个星号；二是，函数体内部使用yield表达式，定义不同的内部状态。async和await是Generator函数的最佳实践，async函数返回一个Promise对象，可以使用then方法添加回调函数。当函数执行的时候，一旦遇到await就会先返回，等到异步操作完成，再接着执行函数体内后面的语句。在Class的内部可以使用get和set关键字，对某个属性设置存值函数和取值函数，并拦截该属性的存取行为。单行定义的对象，最后一个成员不以逗号结尾。多行定义的对象，最后一个成员以逗号结尾。只有模拟现实世界的实体对象时，才使用Object。如果只是需要key: value的数据结构，优先使用map结构。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>javascript</tag>
        <tag>知识点</tag>
        <tag>前端</tag>
        <tag>es6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[create-react-app知识点]]></title>
    <url>%2Fpost%2Fcreate-%20react-app%E7%9F%A5%E8%AF%86%E7%82%B9%2F</url>
    <content type="text"><![CDATA[内置webpack或babel等工具，可以使用eject命令来自定义webpack等配置，但是一旦使用就无法回复默认配置。目前网上有很多第三方工具可以用来实现。webpack只会处理src目录下的文件，public目录下的文件将会直接复制到打包后的目录。用create-react-app创建typescript版本的ant-design模版：yarn create react-app antd-demo-ts --template typescript。]]></content>
      <categories>
        <category>前端</category>
      </categories>
      <tags>
        <tag>知识点</tag>
        <tag>create-react-app</tag>
        <tag>react</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[tcp四层网络模型]]></title>
    <url>%2Fpost%2Ftcp%E5%9B%9B%E5%B1%82%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[tcp 四层网络模型（网络专业也可分为七层）从上到下为 ：应用层负责传送各种最终形态的数据，是直接与用户打交道的层，典型协议是 http，ftp，smtp，telnet。telnet 协议是用来远程登录的，和 ssh类似，不过没有 ssh 安全。传输层负责传送文本数据，典型协议是 tcp，udp。网络层负责分配地址和传送二进制数据，典型协议是 ip。数据链路层负责建立电路连接，是整个网络的物理基础，典型协议是 ppp。ppp 协议是广域网的点对点协议。]]></content>
      <categories>
        <category>网络</category>
      </categories>
      <tags>
        <tag>网络</tag>
        <tag>tcp</tag>
        <tag>模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql的null值]]></title>
    <url>%2Fpost%2Fmysql%E7%9A%84null%E5%80%BC%2F</url>
    <content type="text"><![CDATA[IS NULL 判断当前值为 NULL 时返回 true。IS NOT NULL 判断当前值不为 NULL 时返回 true。不能用 = 或者 != 来判断 NULL 值，得用 ，当比较的的两个值为 NULL 时返回 true。NULL 值与任何其它值的比较（即使是 NULL）永远返回 false，即 NULL = NULL 返回 false。IFNULL 函数1IFNULL(expr1,expr2)如果 expr1 不是 NULL，IFNULL() 返回 expr1，否则它返回 expr2。IFNULL() 返回一个数字或字符串值，取决于它被使用的上下文环境。1IFNULL(age,0)如果 age 字段为 NULL 值，则返回 0。IF 函数1IF(expr1,expr2,expr3)如果 expr1 是 TRUE(expr10 且 expr1NULL)，那么 IF() 返回 expr2，否则它返回 expr3。IF() 返回一个数字或字符串值，取决于它被使用的上下文。1IF(1>2,'yes','no') # 返回 noexpr1 作为整数值被计算，它意味着如果你正在测试浮点或字符串值，你应该使用一个比较操作来做。12IF(0.1,'yes','no') # 返回 no，因为 0.1 被强制转化成整数 0IF(0.10,'yes','no') # 返回 yes]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[查看mysql常用信息]]></title>
    <url>%2Fpost%2F%E6%9F%A5%E7%9C%8Bmysql%E5%B8%B8%E7%94%A8%E4%BF%A1%E6%81%AF%2F</url>
    <content type="text"><![CDATA[查看数据库列表1SHOW DATABASES;查看数据表列表1SHOW TABLES;查看数据表列表1SHOW TABLES;查看数据表属性1SHOW COLUMNS FROM 表名;查看数据表索引信息1SHOW INDEX FROM 表名;查看数据库的性能及统计信息1SHOW TABLE STATUS FROM 数据库名;]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>常用信息</tag>
        <tag>查看</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql的备份与还原]]></title>
    <url>%2Fpost%2Fmysql%E7%9A%84%E5%A4%87%E4%BB%BD%E4%B8%8E%E8%BF%98%E5%8E%9F%2F</url>
    <content type="text"><![CDATA[导出指定数据库到文件1mysqldump -u 用户名 -p 数据库名>文件名.sql由文件导入指定数据库1mysql -u 用户名 -p 数据库名]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>备份</tag>
        <tag>还原</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[oltp和olap]]></title>
    <url>%2Fpost%2Foltp%E5%92%8Colap%2F</url>
    <content type="text"><![CDATA[OLTP联机事务处理，是传统的关系型数据库的主要应用，主要是基本日常的事务处理，例如银行交易等。OLAP联机分析处理，是数据仓库系统的主要应用，支持复杂的分析操作，侧重决策支持，并且提供直观易懂的查询结果，例如统计年度报表等。对比比较项OLTPOLAP用户普通用户决策人员和市场功能事务和查询的日常操作数据统计分析决策实时性高一般数据量一般很大事务性高低并发要求高低数据类型当前最新精确的二维数据由一定时间积累下来的多维汇总数据存取量级小，读/写数十条记录很大，读上百万条记录查询需求简单的事务，由短的原子事务组成，需要具有并行和回滚恢复机制复杂的查询，但主要是纯查询操作]]></content>
      <categories>
        <category>基础拾遗</category>
      </categories>
      <tags>
        <tag>基础拾遗</tag>
        <tag>oltp</tag>
        <tag>olap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql的case-when-then-else-end]]></title>
    <url>%2Fpost%2Fmysql%E7%9A%84case-when-then-else-end%2F</url>
    <content type="text"><![CDATA[两种基本语法简单函数：1CASE 字段名 WHEN 值1 THEN 结果1 WHEN 值2 THEN 结果2 ELSE 其他结果 END简单函数的条件只支持 字段名 = 值 的情况，且始终是同一个字段，对于多个字段或者 IN，!=，这些条件得用下面的搜索函数。搜索函数1CASE WHEN 条件1 THEN 结果1 WHEN 条件2 THEN 结果2 ELSE 其他结果 END搜索函数可以写判断，并且搜索函数只会返回第一个符合条件的值，其他 CASE 被忽略。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>case</tag>
        <tag>when</tag>
        <tag>then</tag>
        <tag>else</tag>
        <tag>end</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[正则表达式]]></title>
    <url>%2Fpost%2F%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[普通字符普通字符包括没有显式指定为元字符的所有可打印和不可打印字符。这包括所有大写和小写字母、所有数字、所有标点符号和一些其他符号。非打印字符非打印字符也可以是正则表达式的组成部分。下表列出了表示非打印字符的转义序列：字符描述\cx匹配由 x 指明的控制字符。例如，\cM 匹配一个 Control-M 或回车符。x 的值必须为 A-Z 或 a-z 之一。否则，将 c 视为一个原义的 c 字符。\f匹配一个换页符。等价于 \x0c 和 \cL。\n匹配一个换行符。等价于 \x0a 和 \cJ。\r匹配一个回车符。等价于 \x0d 和 \cM。\t匹配一个水平制表符。等价于 \x09 和 \cI。\v匹配一个垂直制表符。等价于 \x0b 和 \cK。\s匹配任何空白字符，包括空格，制表符，换页符等等，等价于 [ \f\n\r\t\v]。注意 UNICODE 正则表达式会匹配全角空格符。\S匹配任何非空白字符，等价于 [ \f\n\r\t\v]。特殊字符所谓特殊字符，就是一些有特殊含义的字符，要想得到本来的字符得在前面加一个 \ 来转义。字符描述$匹配输入字符串的结尾位置。如果设置了 RegExp 对象的 Multiline 属性，则 $ 也匹配 \n 或 \r。匹配字符本身需要转义 \$。()标记一个子表达式的开始和结束位置。子表达式可以获取供以后使用。匹配字符本身需要转义 \( 和 \)。*匹配前面的子表达式零次或多次。匹配字符本身需要转义 \*。+匹配前面的子表达式一次或多次。匹配字符本身需要转义 \+。.匹配除换行符 \n 之外的任何单个字符。匹配字符本身需要转义 \. 。[]标记一个中括号表达式的开始。匹配字符本身需要转义 \[ 和 \]。?匹配前面的子表达式零次或一次，或指明一个非贪婪限定符。匹配字符本身需要转义 \?。\将下一个字符标记为特殊字符或原义字符或向后引用或八进制转义符。匹配字符本身需要转义 \。^匹配输入字符串的开始位置，除非在方括号表达式中使用，此时它表示不接受该字符集合。匹配字符本身需要转义 \^。{}标记限定符表达式的开始。匹配字符本身需要转义 \{ 和 \}。|指明多项之间的或者关系。匹配字符本身需要转义 **\**。]]></content>
      <categories>
        <category>基础拾遗</category>
      </categories>
      <tags>
        <tag>基础拾遗</tag>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[markdown查漏补缺]]></title>
    <url>%2Fpost%2Fmarkdown%E6%9F%A5%E6%BC%8F%E8%A1%A5%E7%BC%BA%2F</url>
    <content type="text"><![CDATA[基本语法删除线要加删除线的文字左右分别用两个 ~~ 号包起来1~~这是加删除线的文字~~这是加删除线的文字引用在引用的文字前加 > 即可。引用也可以嵌套，如加两个 >> 三个 >>> 等等，貌似可以无限个，但没神马卵用。123> 引用一个>> 引用两个>>>>>>>>>> 引用好多个引用一个引用两个引用好多个分割线三个或者三个以上的 - 或者 * 都可以。1234-------********高阶语法高阶语法通常依赖当前使用的 markdown 解释器，大部分解释器都支持基础语法，如果小部分不支持高阶语法是没办法使用的。目录将 [TOC] 放到任意位置就会在此处自动生成目录。1[TOC]Latex 数学公式常用数学符号的 LaTeX 表示方法流程图todo列表序列图甘特图技巧换行连续两个以上空格 + 回车。可以用 html转义字符 来代替。还可以直接写 html 的原生语法，可以和 markdown 的语法混写的。缩进字符不断行的空格或半角全角的空格。可以用 html转义字符 来代替。还可以直接写 html 的原生语法，可以和 markdown 的语法混写的。转义字符如果内容中包含 *，|，]]></content>
      <categories>
        <category>基础拾遗</category>
      </categories>
      <tags>
        <tag>基础拾遗</tag>
        <tag>markdown</tag>
        <tag>查漏补缺</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql的锁]]></title>
    <url>%2Fpost%2Fmysql%E7%9A%84%E9%94%81%2F</url>
    <content type="text"><![CDATA[简介锁是计算机协调多个进程或线程并发访问某一资源的机制。锁保证数据并发访问的一致性、有效性。锁冲突也是影响数据库并发访问性能的一个重要因素。锁是 MySQL 在服务器层和存储引擎层的的并发控制。加锁是消耗资源的，锁的各种操作包括：获得锁、检测锁是否是否已解除、释放锁等。锁机制共享锁（读锁）： 其他事务可以读，但不能写。排他锁（写锁）： 其他事务不能读取，也不能写。粒度锁MySQL 不同的存储引擎支持不同的锁机制，所有的存储引擎都以自己的方式显现了锁机制，服务器层完全不了解存储引擎中的锁实现：MyISAM 和 MEMORY（HEAP） 存储引擎采用的是表级锁（table-level locking）。BDB 存储引擎采用的是页面锁（page-level locking），但也支持表级锁。InnoDB 存储引擎既支持行级锁（row-level locking），也支持表级锁，但默认情况下是采用行级锁。默认情况下，表锁和行锁都是自动获得的不需要额外的命令。但是在有的情况下，用户需要明确地进行锁表或者进行事务的控制以便确保整个事务的完整性，这样就需要使用事务控制和锁定语句来完成。表级锁开销小，加锁快，不会出现死锁。锁定粒度大，发生锁冲突的概率最高，并发度最低。存储引擎通过总是一次性同时获取所有需要的锁并且总是按相同的顺序获取表级锁来避免死锁。表级锁更适合于以查询为主并发用户少，只有少量按索引条件更新数据的应用，如 Web 应用。行级锁开销大，加锁慢，会出现死锁。锁定粒度最小，发生锁冲突的概率最低，并发度也最高。最大程度的支持并发，同时也带来了最大的锁开销。在 InnoDB 中，除单个 SQL 组成的事务外，锁是逐步获得的，这就决定了在 InnoDB 中发生死锁是可能的。行级锁只在存储引擎层实现，而 MySQL 服务器层没有实现。行级锁更适合于有大量按索引条件并发更新少量不同数据，同时又有并发查询的应用，如一些在线事务处理（OLTP）系统。页面锁开销和加锁时间界于表锁和行锁之间，会出现死锁。锁定粒度界于表锁和行锁之间，并发度一般。MyISAM 的表锁MyISAM 表锁模式表共享读锁 （Table Read Lock）： 不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写请求。表独占写锁 （Table Write Lock）： 会阻塞其他用户对同一表的读和写操作。MyISAM 表的读操作与写操作之间，以及写操作互相之间是串行的。当一个线程获得对一个表的写锁后，只有持有锁的线程可以对表进行更新操作。 其他线程的读写操作都会等待，直到锁被释放为止。默认情况下，写锁比读锁具有更高的优先级，当一个锁释放时，这个锁会优先给写锁队列中等候的获取锁请求，然后再给读锁队列中等候的获取锁请求。这也正是 MyISAM 表不太适合于有大量更新操作和查询操作应用的原因，因为大量的更新操作会造成查询操作很难获得读锁，从而可能永远阻塞。同时一些需要长时间运行的查询操作，也会使写线程 饿死，应用中应尽量避免出现长时间运行的查询操作，在可能的情况下可以将 SQL 语句进行拆分，使每一步查询都能在较短时间完成从而减少锁冲突。如果复杂查询不可避免，应尽量安排在数据库空闲时段执行，比如一些定期统计可以安排在夜间执行。可以设置改变读锁和写锁的优先级：通过指定启动参数 low-priority-updates，使 MyISAM 引擎默认给予读请求以优先的权利。通过执行命令 SET LOW_PRIORITY_UPDATES=1，使该连接发出的更新请求优先级降低。通过指定 INSERT，UPDATE，DELETE 语句的 LOW_PRIORITY 属性，降低该语句的优先级。给系统参数 max_write_lock_count 设置一个合适的值，当一个表的读锁达到这个值后，MySQL 就暂时将写请求的优先级降低，给读进程一定获得锁的机会。MyISAM 加表锁的方法MyISAM 在执行查询语句（SELECT）之前，会自动给涉及的表加读锁，在执行更新操作（UPDATE，DELETE，INSERT等）之前，会自动给涉及的表加写锁，这个过程并不需要用户干预，因此，用户一般不需要直接用 LOCK TABLE 命令给 MyISAM 表显式加锁。在自动加锁的情况下，MyISAM 总是一次获得 SQL 语句所需要的全部锁，这也正是 MyISAM 表不会出现死锁（Deadlock Free）的原因。MyISAM 存储引擎支持并发插入，以减少给定表的读和写操作之间的争用，如果 MyISAM 表在数据文件中间没有空闲块，则行始终插入数据文件的末尾。在这种情况下，可以自由混合并发使用 MyISAM 表的 INSERT 和 SELECT 语句而不需要加锁，可以在其他线程进行读操作的时候，同时将行插入到 MyISAM 表中。文件中间的空闲块可能是从表格中间删除或更新的行而产生的。如果文件中间有空闲快，则并发插入会被禁用，但是当所有空闲块都填充有新数据时，它又会自动重新启用。 要控制此行为，可以使用 MySQL 的 concurrent_insert 系统变量。当 concurrent_insert 设置为 0 时，不允许并发插入。当 concurrent_insert 设置为 1 时，如果 MyISAM 表中没有空洞，即表的中间没有被删除的行，MyISAM 允许在一个线程读表的同时，另一个线程从表尾插入记录。这也是 MySQL 的默认设置。当 concurrent_insert 设置为 2 时，无论 MyISAM 表中有没有空洞，都允许在表尾并发插入记录。如果使用 LOCK TABLES 显式获取表锁，则可以请求 READ LOCAL 锁而不是 READ 锁，以便在锁定表时，其他会话可以使用并发插入。MyISAM 查看表锁的争用情况可以通过检查 table_locks_waited 和 table_locks_immediate 状态变量来分析系统上的表锁的争夺，如果 Table_locks_waited 的值比较高，则说明存在着较严重的表级锁争用情况。1SHOW STATUS LIKE 'Table%';InnoDB 行锁和表锁InnoDB 的锁模式共享锁： 允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。排他锁： 允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。为了允许行锁和表锁共存，实现多粒度锁机制，InnoDB 还有两种内部使用的意向锁（Intention Locks），这两种意向锁都是表锁：意向共享锁： 事务在给一个数据行加共享锁前必须先取得该表的意向共享锁。意向排他锁： 事务在给一个数据行加排他锁前必须先取得该表的意向排他锁。如果一个事务请求的锁模式与当前的锁兼容，InnoDB 就将请求的锁授予该事务，反之不兼容，则该事务就要等待锁释放。锁模式的兼容情况：当前锁模式/请求锁模式共享锁排他锁意向共享锁意向排他锁共享锁TRUEFALSETRUEFALSE排他锁FALSEFALSEFALSEFALSE意向共享锁TRUEFALSETRUETRUE意向排他锁FALSEFALSETRUETRUEInnoDB 加锁的方法隐式锁定意向锁是 InnoDB 自动加的，不用户干预。对于 UPDATE，DELETE，INSERT 这些更新语句，InnoDB 会自动给涉及数据集加排他锁。对于普通 SELECT 查询语句，InnoDB 不会加任何锁。InnoDB 在事务执行过程中，随时都可以执行锁定，InnoDB 会根据隔离级别在需要的时候自动加锁。锁只有在执行 COMMIT 或者 ROLLBACK 的时候才会释放，并且所有的锁都是在同一时刻被释放。显式锁定事务可以通过以下语句显式给记录集加共享锁或排他锁。共享锁（IN SHARE MODE）：1SELECT * FROM 表名 WHERE 条件 LOCK IN SHARE MODE;其他 SESSION 仍然可以查询记录，并也可以对该记录加 SHARE MODE 的共享锁。但是如果当前事务需要对该记录进行更新操作，则很有可能造成死锁。IN SHARE MODE 子句的作用就是将查找到的数据加上一个 SHARE 锁，这个就是表示其他的事务只能对这些数据进行简单的 SELECT 操作，并不能够进行 DML操作（可以简单理解为增删改查操作）。使用场景：为了确保自己查到的数据没有被其他的事务正在修改，也就是说确保查到的数据是最新的数据，并且不允许其他人来修改数据。但是自己不一定能够修改数据，因为有可能其他的事务也对这些数据用 IN SHARE MODE 的方式上了共享锁。性能影响：该语句是给查找的数据上一个共享锁的功能，它允许其他的事务也对该数据上共享锁，但是不能够允许对该数据进行修改。如果不及时的 COMMIT 或者 ROLLBACK 也可能会造成大量的事务等待。排他锁（IFOR UPDATE）：1SELECT * FROM 表名 WHERE 条件 FOR UPDATE;其他 SESSION 仍然可以查询记录，但是不能对该记录加共享锁或排他锁，而是等待获得锁。在执行这个 SELECT 查询语句的时候，会将对应的索引访问条目进行上排他锁，也就是说这个语句对应的锁就相当于 UPDATE 带来的效果。使用场景：为了让自己查到的数据确保是最新数据，并且查到后的数据只允许自己来修改的时候。性能影响：该语句相当于一个 UPDATE 语句。在业务繁忙的情况下，如果事务没有及时的 COMMIT 或者 ROLLBACK 可能会造成其他事务长时间的等待，从而影响数据库的并发使用效率。InnoDB 行锁的实现方式InnoDB 行锁是通过给索引项加锁来实现的，这种行锁实现特点意味着：只有通过索引条件检索数据，InnoDB 才使用行锁，否则将使用表锁。不论是使用主键索引，唯一索引或普通索引，InnoDB 都会使用行锁来对数据加锁。只有执行计划真正使用了索引才能使用行锁，即便在条件中使用了索引字段，但是否使用索引来检索数据是由 MySQL 通过判断不同执行计划的代价来决定的，如果 MySQL 认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，这种情况下将使用表锁，而不是行锁。因此，在分析锁冲突时，别忘了检查 SQL 的执行计划（可以通过 EXPLAIN 检查 SQL 的执行计划），以确认是否真正使用了索引。由于 MySQL 的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然多个 SESSION 是访问不同行的记录，但是如果是使用相同的索引键，还是会出现锁冲突的（后使用这些索引的 SESSION 需要等待先使用索引的 SESSION 释放锁后，才能获取锁）。InnoDB 查看行锁的争用情况可以通过检查 InnoDB_row_lock 状态变量来分析系统上的行锁的争夺情况：1SHOW STATUS LIKE 'innodb_row_lock%';InnoDB 的间隙锁当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB 会给符合条件的已有数据记录的索引项加锁，键值在条件范围内但并不存在的记录叫做 间隙，InnoDB 也会对这个 间隙 加锁，这种锁机制就是所谓的间隙锁（Next-Key 锁）。很显然，在使用范围条件检索并锁定记录时，InnoDB 这种加锁机制会阻塞符合条件范围内键值的并发插入，这往往会造成严重的锁等待。因此，在实际应用开发中，尤其是并发插入比较多的应用，我们要尽量优化业务逻辑，尽量使用相等条件来访问更新数据，避免使用范围条件。间隙锁可以防止幻读，数据恢复和主从复制的需要。MySQL 通过 BINLOG 录入执行成功的 INSERT，UPDATE，DELETE 等更新数据的 SQL 语句，并由此实现 MySQL 数据库的恢复和主从复制。MySQL 的恢复机制，其实就是在从机器上不断做基于 BINLOG 的恢复，有以下特点：MySQL 的恢复是 SQL 语句级的，也就是重新执行 BINLOG 中记录的 SQL 语句。MySQL 的 BINLOG 是按照事务提交的先后顺序记录的，因此恢复也是按这个顺序进行的。由此可见，MySQL 的恢复机制要求：在一个事务未提交之前，其他并发事务不能插入满足其锁定条件的任何记录，也就是不允许出现幻读。InnoDB 的主动加表锁12345SET AUTOCOMMIT=0; LOCK TABLES 表1 WRITE, 表2 READ, ...; [do something with tables t1 and t2 here]; COMMIT; UNLOCK TABLES;使用 LOCK TABLES 和 UNLOCK TABLES 语句来主动实现对表加锁和解锁。但这都是在服务器层（MySQL Server 层）实现的和存储引擎无关，它们有自己的用途并不能替代事务处理。因此除了禁用了 AUTOCOMMIT 后可以使用，其他情况不建议使用。LOCK TABLES 可以锁定用于当前线程的表。如果表被其他线程锁定，则当前线程会等待，直到可以获取所有锁定为止。UNLOCK TABLES 可以释放当前线程获得的任何锁定。当前线程执行另一个 LOCK TABLES 或当与服务器的连接被关闭时，所有由当前线程锁定的表被隐含地解锁。在用 LOCK TABLES 对 InnoDB 的表加锁时要注意，要先将 AUTOCOMMIT 设为 0，否则 MySQL 不会给表加锁。事务结束前，不要用 UNLOCK TABLES 释放表锁，因为 UNLOCK TABLES 会隐含地提交事务。COMMIT 或 ROLLBACK 并不能释放用 LOCK TABLES 加的表锁，必须用 UNLOCK TABLES 来主动释放表锁。给表显示加表级锁（ InnoDB 表和 MyISAM 都可以），一般是为了在一定程度模拟事务操作，实现对某一时间点多个表的一致性读取。（与 MyISAM 默认的表锁行为类似）在用 LOCK TABLES 给表显式加表锁时，必须同时取得所有涉及到表的锁，并且 MySQL 不支持锁升级。也就是说，在执行 LOCK TABLES 后，只能访问显式加锁的这些表，不能访问未加锁的表。同时，如果加的是读锁那么只能执行查询操作，而不能执行更新操作。其实，在 MyISAM 自动加锁（表锁）的情况下也大致如此，MyISAM 总是一次获得 SQL 语句所需要的全部锁，这也正是 MyISAM 表不会出现死锁（Deadlock Free）的原因。举例：1234567891011# 有一个订单表 **orders**，其中记录有各订单的总金额 **total**，同时还有一个 订单明细表 **order_detail**，其中记录有各订单每一产品的金额小计 **subtotal**，假设我们需要检 查这两个表的金额合计是否相符SELECT SUM(total) FROM orders;SELECT SUM(subtotal) FROM order_detail;# 这时，如果不先给两个表加锁，就可能产生错误的结果，因为第一条语句执行过程中，order_detail 表可能已经发生了改变。因此，正确的方法应该是：LOCK TABLES orders READ LOCAL, order_detail READ LOCAL; SELECT SUM(total) FROM orders; SELECT SUM(subtotal) FROM order_detail; UNLOCK TABLES;# 在 LOCK TABLES 时加了 LOCAL 选项，其作用就是允许当你持有表的读锁时，其他用户可以在满足 MyISAM 表并发插入条件的情况下，在表尾并发插入记录（MyISAM 存储引擎支持并发插入）死锁（Deadlock Free）这里的死锁只针对 InnoDB，因为 MyISAM 是一次性获取所有的锁，所以不会产生死锁。死锁是指两个或多个事务在同一资源上相互占用，并请求锁定对方占用的资源，从而导致恶性循环。当事务试图以不同的顺序锁定资源时，就可能产生死锁。多个事务同时锁定同一个资源时也可能会产生死锁。锁的行为顺序和存储引擎相关。以同样的顺序执行语句，有些存储引擎会产生死锁有些不会。死锁的产生主要是原因：真正的数据冲突和存储引擎的实现方式。数据库系统实现了各种死锁检测和死锁超时的机制。InnoDB 存储引擎能检测到死锁的循环依赖并立即返回一个错误。死锁发生以后，只有部分或完全回滚其中一个事务才能打破死锁，InnoDB 目前处理死锁的方法是，将持有最少行级排他锁的事务进行回滚。所以事务型应用程序在设计时必须考虑如何处理死锁，多数情况下只需要重新执行因死锁回滚的事务即可。发生死锁后，InnoDB 一般都能自动检测到，并使一个事务释放锁并回退，另一个事务获得锁，继续完成事务。但在涉及外部锁，或涉及表锁的情况下，InnoDB 并不能完全自动检测到死锁， 这需要通过设置锁等待超时参数 innodb_lock_wait_timeout 来解决。死锁会影响性能而不是会产生严重错误，因为 InnoDB 会自动检测死锁状况并回滚其中一个受影响的事务。在高并发系统上，当许多线程等待同一个锁时，死锁检测可能导致速度变慢。 有时当发生死锁时，禁用死锁检测（使用 innodb_deadlock_detect 配置选项）可能会更有效，这时可以依赖等待超时参数 innodb_lock_wait_timeout 设置来进行事务回滚。为了在单个 InnoDB 表上执行多个并发写入操作时避免死锁，可以在事务开始时通过为预期要修改的每个行使用 SELECT … FOR UPDATE 语句来获取必要的锁，即使这些行的更改语句是在之后才执行的。在事务中如果要更新记录，应该直接申请足够级别的锁，即排他写锁，而不应先申请共享读锁，然后更新时再申请排他写锁，因为这时候当用户再申请排他写锁时，其他事务可能又已经获得了相同记录的共享读锁，从而造成锁冲突，甚至死锁。如果事务需要修改或锁定多个表，则应在每个事务中以相同的顺序使用加锁语句。在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序来访问表，这样可以大大降低产生死锁的机会通过 SELECT … LOCK IN SHARE MODE 获取行的共享读锁后，如果当前事务再需要对该记录进行更新操作，则很有可能造成死锁。根据具体情况适当的调整事务隔离级别。如果出现死锁，可以用 SHOW INNODB STATUS 命令来确定最后一个死锁产生的原因。返回结果中包括死锁相关事务的详细信息，如引发死锁的 SQL 语句，事务已经获得的锁，正在等待什么锁，以及被回滚的事务等。据此可以分析死锁产生的原因和改进措施。尽量使用较低的隔离级别。精心设计索引， 并尽量使用索引访问数据， 使加锁更精确， 从而减少锁冲突的机会。选择合理的事务大小，小事务发生锁冲突的几率也更小。尽量用相等条件访问数据，这样可以避免间隙锁对并发插入的影响。不要申请超过实际需要的锁级别。除非必须，查询时不要显示加锁。MySQL 可以实现事务中的查询不用加锁优化事务性能。但只在 COMMITTED READ（读提交）和 REPEATABLE READ（可重复读）两种隔离级别下工作。对于一些特定的事务，可以使用表锁来提高处理速度或减少死锁的可能。乐观锁（Optimistic Lock）和悲观锁（Pessimistic Lock）乐观锁(Optimistic Lock)：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。 乐观锁不能解决脏读的问题。顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库如果提供类似于 write_condition 机制的其实都是提供的乐观锁。悲观锁（Pessimistic Lock）：假设一定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会等待，直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。一言蔽之：乐观锁先执行后上锁，悲观锁先上锁后执行。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>锁</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql事务]]></title>
    <url>%2Fpost%2Fmysql%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[简介MySQL 事务主要用于处理操作量大，复杂度高的数据。比如说，在人员管理系统中删除一个人员，既需要删除人员的基本资料，也要删除和该人员相关的信息，如信箱，文章等等，这些数据库操作语句就构成一个事务。在 MySQL 中只有使用了 InnoDB 数据库引擎的数据库或表才支持事务。事务处理可以用来维护数据库的完整性，保证成批的 SQL 语句要么全部执行，要么全部不执行。事务用来管理 INSERT，UPDATE，DELETE 语句。MySQL 默认事务都是自动提交的，即执行 SQL 语句后就会马上执行 COMMIT 操作。因此要显式地开启一个事务必须使用命令 BEGIN 或 START TRANSACTION，或者执行命令 SET AUTOCOMMIT=0，用来禁止使用当前会话的自动提交，SET AUTOCOMMIT=1 可以再次设置为自动提交。事务具有的四个特性原子性： 一个事务（TRANSACTION）中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。事务在执行过程中发生错误，会被回滚（ROLLBACK）到事务开始前的状态，就像这个事务从来没有执行过一样。一致性： 在事务开始之前和事务结束以后，数据库的完整性没有被破坏。这表示写入的资料必须完全符合所有的预设规则，这包含资料的精确度、串联性以及后续数据库可以自发性地完成预定的工作。隔离性： 数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。事务隔离分为不同级别，InnoDB 存储引擎提供的包括：读未提交（READ UNCOMMITTED ）：事务 A 未提交的数据，事务 B 可以读取到， 这里读取到的数据叫做 脏数据。这种隔离级别最低，这种级别一般只在理论上存在实际中很少使用，数据库隔离级别一般都高于该级别。读已提交（READ COMMITTED）：只有事务 A已经提交的数据，事务 B 才能读取到，这种隔离级别高于读未提交，这种级别可以避免 脏数据，但是会导致 不可重复读取。可重复读（REPEATABLE READ）：即使事务 A 提交之后的数据，事务 B 也读取不到，事务 B 是可重复读取数据，这种隔离级别高于读已提交可以避免 不可重复读取，但是会导致 幻读。是 MySQL 的默认隔离级别。串行化（SERIALIZABLE）：事务 A 在操作数据库时，事务 B 只能排队等待，这种隔离级别很少使用，吞吐量太低用户体验差，这种级别可以避免 幻读，每一次读取的都是数据库中真实存在数据，事务 A 与事务 B 串行而不并发，即一个一个来不能同时运行。持久性： 事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。事务控制语句BEGIN 或 START TRANSACTION 显式地开启一个事务。COMMIT 也可以使用 COMMIT WORK，不过二者是等价的。COMMIT 会提交事务，并使已对数据库进行的所有修改成为永久性的。ROLLBACK 也可以使用 ROLLBACK WORK，不过二者是等价的。回滚会结束用户的事务，并撤销正在进行的所有未提交的修改。SAVEPOINT identifier，SAVEPOINT 允许在事务中创建一个保存点，一个事务中可以有多个 SAVEPOINT。RELEASE SAVEPOINT identifier 删除一个事务的保存点，当没有指定的保存点时，执行该语句会抛出一个异常。ROLLBACK TO identifier 把事务回滚到保存点。SET TRANSACTION 用来设置事务的隔离级别。四种隔离级别产生的并发问题隔离级别越高，越能保证数据的完整性和一致性，但是对并发性能的影响也越大。当隔离级别为串行化（SERIALIZABLE）时可以保证数据的绝对完整但此时读写数据都会锁住整张表，因此效率会大大降低。脏读： 事务 A 读取了事务 B 更新的数据，然后 B 回滚操作，那么 A 读取到的数据是脏数据。不可重复读： 事务 A 多次读取同一数据，事务 B 在事务 A 多次读取的过程中，对数据作了更新并提交，导致事务 A 多次读取同一数据时，结果不一致。幻读： 事务 A 多次读取同一数据，事务 B 在事务 A 多次读取的过程中，插入或删除了一些数据并提交，导致事务 A 多次读取同一数据时，发现多了或少了一些数据。不可重复读的和幻读很容易混淆，不可重复读侧重于修改，幻读侧重于新增或删除。解决不可重复读的问题只需锁住满足条件的行，解决幻读需要锁表。隔离级别脏读不可重复读幻读读未提交（READ UNCOMMITTED ）TRUETRUETRUE读已提交（READ COMMITTED）FALSETRUETRUE可重复读（REPEATABLE READ）FALSEFALSETRUE串行化（SERIALIZABLE）FALSEFALSEFALSE]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>事务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql的正则表达式regexp]]></title>
    <url>%2Fpost%2Fmysql%E7%9A%84%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8Fregexp%2F</url>
    <content type="text"><![CDATA[模式描述^匹配输入字符串的开始位置。如果设置了 RegExp 对象的 Multiline 属性，^ 也匹配 \n 或 \r 之后的位置。$匹配输入字符串的结束位置。如果设置了 RegExp 对象的 Multiline 属性，$ 也匹配 \n 或 \r 之前的位置。.匹配除 \n 之外的任何单个字符。要匹配包括 \n 在内的任何字符，请使用象 [.\n] 的模式。[…]字符集合。匹配所包含的任意一个字符。例如，[abc] 可以匹配 plain 中的 a。[^…]负值字符集合。匹配未包含的任意字符。例如， [^abc] 可以匹配 plain 中的 p。p1|p2|p3匹配 p1 或 p2 或 p3。例如，z|food 能匹配 z 或 food。(z|f)ood 则匹配 zood 或 food。*匹配前面的子表达式零次或多次。例如，zo* 能匹配 z 以及 zoo。* 等价于 {0,}。+匹配前面的子表达式一次或多次。例如，zo+ 能匹配 zo 以及 zoo，但不能匹配 z。+ 等价于 {1,}。{n}n 是一个非负整数。匹配确定的 n 次。例如，o{2} 不能匹配 Bob 中的 o，但是能匹配 food 中的两个 o。{n,m}m 和 n 均为非负整数，其中 n]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>regexp</tag>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql的执行顺序]]></title>
    <url>%2Fpost%2Fmysql%E7%9A%84%E6%89%A7%E8%A1%8C%E9%A1%BA%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[12345678910111213SELECT DISTINCT 字段1,字段2 FROM 表1 JOIN 表2 ON 表1.字段3=表2.字段4WHERE 条件1,条件2GROUP BY 字段5HAVING 条件3,条件4ORDER BY 字段6LIMIT 开始位置,限制长度MySQL 解释器的执行顺序为：FROMONJOINWHEREGROUP BYHAVINGSELECTDISTINCTORDER BYLIMIT]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>顺序</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql模糊查询]]></title>
    <url>%2Fpost%2Fmysql%E6%A8%A1%E7%B3%8A%E6%9F%A5%E8%AF%A2%2F</url>
    <content type="text"><![CDATA[不加任何匹配的话就等价于 =。% 通配符表示任何字符出现任意次，可以是 0 次。_ 通配符表示任何字符出现 1 次。12345678SELECT * FROM user WHERE username LIKE 'test%'; # 以 test 字符串开头的，包括 test 本身，这种方式可以走索引SELECT * FROM user WHERE username LIKE '%test'; # 以 test 字符串结尾的，包括 test 本身SELECT * FROM user WHERE username LIKE '%test%'; # 包含 test 字符串的，包括 test 本身SELECT * FROM user WHERE username LIKE 'test_'; # 以 test 字符串开头的，且后面必须跟着一个字符，这种方式可以走索引SELECT * FROM user WHERE username LIKE '_test'; # 以 test 字符串结尾的，且前面必须跟着一个字符SELECT * FROM user WHERE username LIKE '_test_'; # 包含 test 字符串的，且前面和后面必须分别跟着一个字符SELECT * FROM user WHERE username LIKE '%[a-z]%'; # 包含小写字母的SELECT * FROM user WHERE username LIKE '%[!0-9]%'; # 不包含数字的注意空格也会被识别出来，但是不能匹配 NULL。是否区分大小写这个得看 MySQL 的配置，或者使用 BINARY 操作符来进行二进制的匹配。或者使用 UPPER 操作符全部转化成大写字母，然后配合 CONCAT 操作符将多个字符串连起来。12# 中英文混合且忽略英文大小写的模糊匹配SELECT * FROM username WHERE UPPER(username) LIKE BINARY CONCAT('%',UPPER(‘a中文b’)，‘%’);]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>like</tag>
        <tag>模糊查询</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql的in和exists]]></title>
    <url>%2Fpost%2Fmysql%E7%9A%84in%E5%92%8Cexists%2F</url>
    <content type="text"><![CDATA[EXISTSEXISTS 对外表用 LOOP 逐条循环查询，每次查询都会查看 EXISTS 的条件语句，当 EXISTS 里的条件语句能够返回记录时(无论记录是多少条，只要能返回)，条件就为真，返回当前 LOOP 到的这条记录，反之如果 EXISTS 里的条件语句不能返回记录行，则当前 LOOP 到的这条记录被丢弃，EXISTS 里的语句就像一个 WHERE 条件，当能返回结果时为 TRUE否则为 FALSE。ININ 相当于多个 OR 条件的叠加。但是 IN 的条件只支持一个字段，而 EXISTS 则没有限制。性能比较EXISTS1SELECT * FROM 表1 WHERE EXISTS (SELECT * FROM 表2 WHERE 表2.id = 表1.id); # 查询主要是用到了表2的索引，表1对查询的效率影响不大。IN1234SELECT * FROM 表1 WHERE 表1.id IN (SELECT id FROM 表2);# 假设这里表2的所有id为 1，2，3 则上面语句可以转化成SELECT * FROM 表1 WHERE 表1.id = 1 OR 表1.id = 2 OR 表1.id = 3; # 查询主要是用到了表1的索引，表2对查询的效率影响不大。NOT EXISTS1SELECT * FROM 表1 WHERE NOT EXISTS (SELECT * FROM 表2 WHERE 表2.id = 表1.id); # 查询主要是用到了表2的索引，表1对查询的效率影响不大。NOT IN1234SELECT * FROM 表1 WHERE 表1.id NOT IN (SELECT id FROM 表2);# 假设这里表2的所有id为 1，2，3 则上面语句可以转化成SELECT * FROM 表1 WHERE 表1.id != 1 OR 表1.id != 2 OR 表1.id != 3; # 因为 != 不会走索引，所以效率很差IN 语句是把外表和内表作 HASH 连接，而 EXISTS 语句是对外表作 LOOP 循环，再对内表进行查询。所以得出结论：内外表大小差不多，用 IN 和 EXISTS 都行。内表大用 EXISTS，外表大用 IN。无论什么情况 NOT EXISTS 都比 NOT IN 效率高，因为前者走索引后者没有。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>in</tag>
        <tag>exists</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql的with-rollup和coalesce函数配合group-by实现分组之后汇总]]></title>
    <url>%2Fpost%2Fmysql%E7%9A%84with-rollup%E5%92%8Ccoalesce%E5%87%BD%E6%95%B0%E9%85%8D%E5%90%88group-by%E5%AE%9E%E7%8E%B0%E5%88%86%E7%BB%84%E4%B9%8B%E5%90%8E%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[WITH ROLLUP 可以实现在分组统计数据基础上再进行相同的统计（SUM，AVG，COUNT 等）。1SELECT name, SUM(singin) as singin_count FROM employee_tbl GROUP BY name WITH ROLLUP;其中记录 NULL 表示所有人的登录次数。可以使用 COALESCE 来设置一个可以取代 NULL 的名称，语法如下：1select COALESCE(a,b,c);如果 a==NULL，则选择 b。如果 b==NULL，则选择 c。如果 a!=NULL，则选择 a。如果 a，b，c 都为 NULL ，则返回为 NULL（没意义）。所以可以结合起来改造上面语句，用 “总数” 来替换 NULL：1SELECT COALESCE(name, '总数'), SUM(singin) as singin_count FROM employee_tbl GROUP BY name WITH ROLLUP;]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>with rollup</tag>
        <tag>coalesce</tag>
        <tag>group by</tag>
        <tag>函数</tag>
        <tag>分组</tag>
        <tag>汇总</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql的用户设置]]></title>
    <url>%2Fpost%2Fmysql%E7%9A%84%E7%94%A8%E6%88%B7%E8%AE%BE%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[添加用户12345INSERT INTO user (host, user, password, select_priv, insert_priv, update_priv) VALUES ('localhost', 'guest', PASSWORD('123'), 'Y', 'Y', 'Y');在 5.7 版本中 user 表的 password 字段已换成了 authentication_string。使用 MySQL 自带的 PASSWORD() 函数来对密码进行加密。在 8.0 版本中 PASSWORD() 加密函数已经移除了，可以使用自带的 MD5() 函数代替。执行完之后得执行 FLUSH PRIVILEGES ，这个命令执行后会重新载入授权表。如果你不使用该命令就无法使用新创建的用户来连接 MySQL 服务器，除非重启。可以在创建用户时为用户指定权限，例如上述代码中的 select_priv，insert_priv，update_priv 字段，在对应的权限列中，在插入语句中设置为 ‘Y’ 即可，用户权限列表如下：Select_privInsert_privUpdate_privDelete_privCreate_privDrop_privReload_privShutdown_privProcess_privFile_privGrant_privReferences_privIndex_privAlter_priv增删改查操作类似，都是对 user 表进行 INSERT，DELETE，UPDATE，SELECT 这些操作。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>用户</tag>
        <tag>设置</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql运算符]]></title>
    <url>%2Fpost%2Fmysql%E8%BF%90%E7%AE%97%E7%AC%A6%2F</url>
    <content type="text"><![CDATA[算术运算符运算符描述+加法-减法*乘法/除法（返回精确到小数点后四位浮点数）DIV除法（返回整数，舍去小数部分）%，MOD取余12345678910111213141516171819# 加法SELECT 1 + 2; # 3# 减法SELECT 1 - 2; # -1# 乘法SELECT 2 * 3; # 6# 除法（返回精确到小数点后四位浮点数）SELECT 3 / 2; # 1.5000# 除法（返回整数，舍去小数部分）SELECT 3 DIV 2; # 1# 取余SELECT 3 % 2; # 1SELECT 3 MOD 2; # 1SELECT MOD(3, 2); # 1比较运算符运算符描述=等于严格比较两个NULL值是否相等，两个操作码均为 NULL 时，其所得值为 1，而当一个操作码为 NULL 时，其所得值为 0，!=不等于>大于=大于等于 1; # 1# 按位左移SELECT 3 < ，>=，]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>运算符</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql的外键]]></title>
    <url>%2Fpost%2Fmysql%E7%9A%84%E5%A4%96%E9%94%AE%2F</url>
    <content type="text"><![CDATA[简介MySQL 通过外键约束来保证表与表之间的数据的完整性和准确性。一个表中的 FOREIGN KEY 指向另一个表中的 UNIQUE KEY(唯一约束的键，不一定是 PRIMARY KEY)。FOREIGN KEY 约束用于预防破坏表之间连接的行为。FOREIGN KEY 约束也能防止非法数据插入外键列，因为它必须是它指向的那个表中的值之一。使用条件两个表必须是 InnoDB 表，MyISAM 表暂时不支持外键。主表的字段必须是唯一键，不一定要是主键，只要具有唯一性约束就行了。关联的两个字段必须是 InnoDB 下的相似类型，即 INT 和 TINYINT 可以，INT 和 CHAR 就不行。外键的字段必须建立索引，新版本已经可以自动创建索引了，不用手动创建了。避免使用复合键，也就是说从表能够同一时候引用多个主表的字段作为一个外键，但是一般不推荐这样的做法。创建123456789CREATE TABLE 表1( 字段1 int NOT NULL, 字段2 int, CONSTRAINT symbol PRIMARY KEY (字段1), FOREIGN KEY (字段2) REFERENCES 表2(字段1) ON 触发事件1 具体操作1 ON 触发事件2 具体操作2)表1的字段2是外键，与表2的字段1（唯一键，一般是主键）相关联。symbol 可以为选填，手动指定的话必须保证唯一性，不写就由 MySQL 自动生成，建议自动生成触发事件有如下值：DELETE 删除时UPDATE 更新时具体操作有如下值：RESTRICT 限制外表中的外键改动CASCADE 跟随外键改动SET NULL 设空值SET DEFAULT 设默认值NO ACTION 无动作，默认触发事件和具体操作为可选项，但必须成对出现，且可有多个。修改12345ALTER TABLE 表1ADD CONSTRAINT symbol FOREIGN KEY (字段2)REFERENCES 表2(字段1)ON 触发事件1 具体操作1ON 触发事件2 具体操作2删除12ALTER TABLE 表1DROP FOREIGN KEY 字段2]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>外键</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql的三范式]]></title>
    <url>%2Fpost%2Fmysql%E7%9A%84%E4%B8%89%E8%8C%83%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[基本概念第一范式： 当关系模式 R 的所有属性都不能在分解为更基本的数据单位时，称 R 是满足第一范式的，简记为 1NF 。满足第一范式是关系模式规范化的最低要求，否则，将有很多基本操作在这样的关系模式中实现不了。简而言之：字段不可分 。第二范式： 如果关系模式 R 满足第一范式，并且 R 的所有非主属性都完全依赖于 R 的每一个候选关键属性，称 R 满足第二范式，简记为 2NF。简而言之：有主键，非主键字段完全依赖主键 。第三范式： 假设 R 是一个满足第一范式条件的关系模式，X 是 R 的任意属性集，如果 X 非传递依赖于 R 的任意一个候选关键字，称 R 满足第三范式，简记为 3NF。简而言之：非主键字段之间不能相互依赖 。第一范式每一列属性都是不可再分的属性值，确保每一列的原子性。两列的属性相近或相似或一样，尽量合并属性一样的列，确保不产生冗余数据。第二范式每一行的数据只能与其中一列相关，即一行数据只做一件事。只要数据列中出现数据重复，就要把表拆分开来。第三范式数据不能存在传递关系，即每个属性都跟主键有直接关系而不是间接关系。设计原则三大范式只是一般设计数据库的基本理念，可以建立冗余较小、结构合理的数据库。如果有特殊情况，当然要特殊对待，数据库设计最重要的是看需求跟性能，需求 > 性能 > 表结构。所以不能一味的去追求范式建立数据库。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>三范式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql性能调优]]></title>
    <url>%2Fpost%2Fmysql%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%2F</url>
    <content type="text"><![CDATA[适当地使用索引，索引可以优化查询效率，但是过多的话影响修改效率。使用复合索引，优先级从左到右。坚决不要涉及到 NULL 值，因为 NULL 值不会走索引。MySQL 的一条查询只能使用一个索引，例如：当 WHERE 条件使用索引时，后面 ORDER BY 的索引将不会使用。尽量避免模糊查询，因为 %VALUE% 不会走索引，但是 VALUE% 可以用索引。实在需要 %VALUE 这种形式可以在使用符合索引构成覆盖索引，性能至少会比全表扫描好。或者根据需求拆成多次查询。不要使用 非操作， 诸如 NOT， , != 这些操作是不会走索引的。不要在 WHERE子句 中的 = 左边进行任何操作，诸如 WHERE YEAR(birthday) < 2017 这样的操作是不会走索引的。多个条件时慎用 OR ， 当一个条件有索引而另一个没有时，就不会走索引了，可以分别查询然后用 UNION 将结果集连接起来。用 EXISTS 代替 IN，前者效率比较高。字段类型越简单查询效率越高，例如：主键是 INT 类型就比 CHAR 类型快很多。NVARCHAR 相比 VARCHAR 可以存储 UNICODE 字符，但是也因此存储容量少了一半，同理 NCHAR 对比 CHAR。NVARCHAR/VARCHAR 相比 NCHAR/CHAR 字符是不固定长度的，因此从占用空间上来考虑会比较高效，但是正因为 NCHAR/CHAR 是固定长度的所以索引效率会比较高，这个得根据实际情况来考虑平衡。绝对不要用 * ，除非真的要查全部数据，否则每条 SQL 都应该只查询需要的数据，不应该有任何的多余字段。避免频繁创建和删除 临时表，以减少系统表资源的消耗。临时表 并不是不可使用，适当地使用它们可以使某些例程更有效，例如：当需要重复引用大型表或常用表中的某个数据集时。但是，对于一次性事件， 最好使用导出表。在新建 临时表 时，如果一次性插入数据量很大，那么可以使用 SELECT INTO 代替 CREATE TABLE，避免造成大量 LOG ，以提高速度；如果数据量不大，为了缓和系统表的资源，应先 CREATE TABLE，然后 INSERT。如果使用到了 临时表 ，在存储过程的最后务必将所有的 临时表 显式删除，先 TRUNCATE TABLE ，然后 DROP TABLE ，这样可以避免系统表的较长时间锁定。尽量避免大事务操作，提高系统并发能力。拆分大的 DELETE 或 INSERT 语句为小的语句，批量提交 SQL 语句。因为删除和更新操作会锁表，当数据量过大耗时太久时，很可能会造成服务的崩溃。用 JOIN 代替 子查询。用 UNION 代替 临时表。使用 外键 来保证数据的同步。MySQL 的解析器按照从左往右的顺序处理 FROM 子句中的表名， 写在最前面的表将被最先处理，在 FROM 子句中包含多个表的情况下,你必须选择记录条数最少的表放在最前面：如果多个表是完全无关系的话，将记录和列名最少的表放在最前面然后依次类推，如果表之间是有关系的话，将引用最多的表放在最前面然后依次类推。对于 WHERE 子句，也是按照从左往右的顺序处理，所以过滤掉大量数据的条件应该放在最左边，表之间的连接应该放在最右边。用 WHERE 子句替换 HAVING 子句，因为 WHERE 先执行，HAVING 后执行。使用 >= 代替 > ，例如：WHERE a > 10 改成 WHERE a >= 10.0000001。删除全表时，用 TRUNCATE 比 DELETE 效率更好。DELETE 会一行一行的删除数据，而 TRUNCATE 则会按照原有的表结构重新创建一张新表。但是 TRUNCATE 不会生成 MySQL 的日志，且无法恢复数据。尽量多使用 COMMIT，只要有可能就对程序中每个 DELETE，INSERT，UPDATE 使用 COMMIT，即应该将事务尽量拆分，这样不会因大量占用资源导致锁，系统会因为 COMMIT 所释放的资源而大大提高效率。有条件的使用 UNION ALL 代替 UNION 提高效率。这两者的唯一区别就是后者会去除重复的值。当连接多个表时对表使用别名，子查询也是如此，因为这样可以加快数据库引擎查找表的时间。尽量少用 联合查询， 子查询， 触发器， 事务 这些相对复杂的操作，数据库设计时尽量做到能用最简单的语句来完成查询。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>性能</tag>
        <tag>调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql的存储引擎innodb和myisam之间的比较]]></title>
    <url>%2Fpost%2Fmysql%E7%9A%84%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8Einnodb%E5%92%8Cmyisam%E4%B9%8B%E9%97%B4%E7%9A%84%E6%AF%94%E8%BE%83%2F</url>
    <content type="text"><![CDATA[MyISAM 强调的是性能，其执行数度比 InnoDB 更快，占用空间更小，但是不提供事务支持。InnoDB 提供事务支持事务，外键等高级数据库功能。如果执行大量的 SELECT 操作，MyISAM 是更好的选择。如果执行大量的 INSERT 或 UPDATE，出于性能方面的考虑，应该使用 InnoDB 表。MyISAM 适合查询以及插入为主的应用，InnoDB 适合频繁修改，读写密集以及涉及到安全性较高的应用。清空整个表 DELETE FROM 表1 时，InnoDB 是一行一行的删除，效率非常慢。MyISAM 则会重建表。可以用 TRUNCATE TABLE 表1 来代替。LOAD 操作（导入数据）对 InnoDB 是不起作用的，解决方法是首先把 InnoDB 改成 MyISAM ，导入数据后再改成 InnoDB 表，但是对于使用的额外的 InnoDB 特性（例如外键）的表不适用。对于字段的 AUTO_INCREMENT 特性，MyISAM 比 InnoDB 支持的更好更快。InnoDB 中必须包含只有该字段的索引，但是在 MyISAM 表中可以和其他字段一起建立联合索引。对于 COUNT 操作，因为 MyISAM 会自动将行数另外保存，所以搜索的时候直接取出来就可以了，所以更快。而 InnoDB 得全表扫描一遍来计算一下行数。但是当 SELECT COUNT(*) 语句带有 WHERE 条件时，MyISAM 也会像 InnoDB 一样全表扫描从而影响性能。MyISAM 只提供表锁，而 InnoDB 支持行锁和不加锁读取，但是当 MySQL 不能确定要执行的 SQL 语句要扫描的范围时 InnoDB 同样会锁全表。MySQL 在 5.1 之前默认存储引擎是 MyISAM，之后是 InnoDB。在 5.6 版本之前只有MyISAM 支持 FULLTEXT 类型的索引，之后 InnoDB 也支持了。这可以极大的优化了模糊查询 LIKE 的效率。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>存储引擎</tag>
        <tag>innodb</tag>
        <tag>myisam</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql的临时表]]></title>
    <url>%2Fpost%2Fmysql%E7%9A%84%E4%B8%B4%E6%97%B6%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[MySQL 默认外部临时表MySQL 临时表在我们需要保存一些临时数据时是非常有用的，主要用于对大数据量的表上作一个子集，提高查询效率。临时表只在当前连接可见，当关闭连接时，Mysql 会自动删除表并释放所有空间。 PHP 方式调用 MySQL 时，脚本结束之后临时表就被销毁了，其他情况都是在客户端链接关闭之后才会销毁，当然也可以手动销毁。使用方式和普通表类似，不过还是有一些区别的：创建临时表的时候加上 TEMPORARY。1CREATE TEMPORARY TABLE 表名()使用 SHOW TABLES 命令是看不到创建的临时表的。使用 SHOW CREATE TABLE 可以查看临时表。在 information_schema 中也不存在临时表的信息。退出 mysql 连接之后再登陆进去时，临时表已经被销毁了。1mysql> SELECT * FROM 表名; # ERROR 1146: Table '表名' doesn't exist或者使用 DROP 表名 来手动销毁临时表也一样。12mysql> DROP TABLE 表名;mysql> SELECT * FROM 表名; # ERROR 1146: Table '表名' doesn't exist不同连接的临时表所属各自的作用域，所以不用担心表名重复，如果同一个连接中的临时表和正常表名称相同，则正常表隐藏，临时表将会覆盖掉它。创建临时表不会引发通常的 COMMIT 事务提交。临时表不支持 MySQL 的集群。临时表不能使用 RENAME 来重命名，只能用 ALTER TABLE 表名1 表名2 这种形式。同一个查询语句中同一个临时表只能引用一次，但是可以有多个不同的临时表。同一个用户存储函数中同一个临时表也只能引用一次。会对 MySQL 的主从复制有一定的影响。临时表的引擎类型只能是：MEMORY（HEAP），MYISAM，MERGE，INNODB外部内存表在创建临时表时声明引擎类型为 MEMORY（HEAP） ，则 MySQL 会在内存中创建该临时表，即内存表。1CREATE TEMPORARY TABLE 表名 (...) TYPE = HEAP;内存表的 MEMORY（HEAP） 引擎不支持 BLOB/TEXT 数据类型的字段。临时表的表和数据都存储在内存中，而内存表的表建在磁盘中而数据存储在内存中。内存表和临时表的容量大小都可以在 MySQL 的配置中设置，当内存表的数据使用超出容量时会报错，临时表则会把数据写入到磁盘中，此时需要大量的 I/O 操作，引起性能的下降。临时表一般比较少用，一般只在确定不能用索引的时候或者在存储过程中某些固定数据使用次数非常多的时候使用临时表。通常是在应用程序中动态创建或者由 MySQL 内部根据执行计划需要自己创建。内存表则大多作为 Cache 来使用。如今随着 memcache ，redis 等第三方 Cache 的流行，越来越少选择使用内存表。内部临时表在某些情况下，MySQL 服务器会自动创建内部临时表。使用 EXPLAIN 查看查询语句的执行计划，如果 extra 列显示 “using temporary” 即使用了内部临时表。内部临时表的创建条件：UNION 查询。用到 TEMPTABLE 算法或者是 UNION 查询中的视图。ORDER BY 和 GROUP BY 的子句不一样时。表连接中 ORDER BY 的列不是驱动表中的时候。DISTINCT 查询并且加上 ORDER BY 时。SQL 中用到 SQL_SMALL_RESULT 选项时。FROM 中的子查询。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>临时表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql高可用架构设计]]></title>
    <url>%2Fpost%2Fmysql%E9%AB%98%E5%8F%AF%E7%94%A8%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>高可用</tag>
        <tag>架构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql处理重复数据]]></title>
    <url>%2Fpost%2Fmysql%E5%A4%84%E7%90%86%E9%87%8D%E5%A4%8D%E6%95%B0%E6%8D%AE%2F</url>
    <content type="text"><![CDATA[防止表中出现重复数据可以在 MySQL 数据表中设置指定的字段为 PRIMARY KEY（主键） 或者 UNIQUE（唯一） 索引来保证数据的唯一性。如果想设置表中多个字段数据不能重复，可以设置联合主键或者联合唯一索引模式来设置数据的唯一性，此时那个键的默认值就不能为 NULL，得设置为 NOT NULL。1234567CREATE TABLE 表名( 字段1 CHAR(20) NOT NULL, 字段2 CHAR(20) NOT NULL, 字段3 CHAR(10), PRIMARY KEY/UNIQUE (字段1, 字段2));如果设置了唯一索引，那么在插入重复数据时，SQL 语句将无法执行成功,并抛出错。此时可以使用 INSERT IGNORE INTO，与 INSERT INTO 的区别就是 INSERT IGNORE INTO 会忽略数据库中已经存在的数据，如果数据库没有数据就插入新的数据，如果有数据的话就跳过这条数据。这样就可以保留数据库中已经存在数据，达到在间隙中插入数据的目的。1INSERT IGNORE INTO 表名 (字段1, 字段2) VALUES(值1, 值2);如果在设置了记录的唯一性之后，INSERT IGNORE INTO 插入重复数据时将不返回错误，只以警告形式返回。 而使用 REPLACE INTO 时，如果重复的记录有主键或者唯一索引，则先删除掉该条记录再插入新记录。统计重复数据1SELECT COUNT(*) as 别名, 字段1, 字段2 FROM 表名 GROUP BY 字段1, 字段2 HAVING 别名 > 1;确定哪些列包含的值可能会重复。用 COUNT(*) 查询这些列的数量。再用 GROUP BY 对这些列进行分组。配合 HAVING 过滤出重复数大于 1 的列。过滤重复数据12345# 使用 DISTINCT 来去重SELECT DISTINCT 字段1,字段2 FROM 表名;# 使用 GROUP BY 来去重SELECT 字段1,字段2 FROM 表名 GROUP BY (字段1,字段2);删除重复数据12345678910# 新建一张不重复的表来替换原有的重复表CREATE TABLE 表2 SELECT 字段1,字段2,字段3 FROM 表1 GROUP BY (字段1,字段2,字段3);DROP TABLE 表1;ALTER TABLE 表2 RENAME TO 表1;# 添加主键或者唯一索引来删除重复记录ALTER IGNORE TABLE 表名 ADD PRIMARY KEY/UNIQUE (字段1,字段2,字段3);# 使用子查询删除大于最小值的数据DELETE FROM 表1 别名1 WHERE 别名1.字段1 > (SELECT MIN(别名2.字段1) FROM 表2 别名2 WHERE 别名2.主键字段 = 别名1.主键字段);]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>重复数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql的alter命令]]></title>
    <url>%2Fpost%2Fmysql%E7%9A%84alter%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[删除表字段1ALTER TABLE 表名 DROP 字段名;如果数据表中只剩余一个字段则无法使用 DROP 来删除字段。添加表字段1ALTER TABLE 表名 ADD 字段名 INT(11);默认情况下，ADD 命令下字段会自动添加到数据表字段的末尾。如果需要指定新增字段的位置，可以使用 MySQL 提供的关键字 FIRST (指定位置为第一列)， AFTER 字段名（指定位置为某个字段之后）。12345# 添加在第一列ALTER TABLE 表名 ADD 字段名 INT(11) FIRST;# 在字段1后面添加字段2ALTER TABLE 表名 ADD 字段2 INT(11) AFTER 字段1;如果想重置数据表字段的位置就需要先使用 DROP 删除字段然后使用 ADD 来添加字段并设置位置。修改表字段MODIFY 和 CHANGE 都可以用来修改表字段。12345# 将指定字段改为 CHAR(10) 类型 且指定注释ALTER TABLE 表名 MODIFY 字段名 CHAR(10) COMMENT '注释';# 将字段1名称改为字段2，且指定为 CHAR(10) 类型ALTER TABLE 表名 CHANGE 字段1 字段2 BIGINT;当添加或修改字段时，可以指定是否包含值或者是否设置默认值。如果不设置默认值，MySQL 会自动设置该字段默认为 NULL。1ALTER TABLE 表名 MODIFY 字段名 BIGINT NOT NULL AUTO_INCREMENT DEFAULT 100;修改字段默认值1ALTER TABLE 表名 ALTER 字段名 SET DEFAULT 1000;也可以使用 DROP 来删除字段的默认值。1ALTER TABLE 表名 ALTER 字段名 DROP DEFAULT;修改数据表存储引擎12# 修改指定表的存储引擎为 MYISAMALTER TABLE 表名 ENGINE = MYISAM;修改表名12# 将表1的名称修改为表2ALTER TABLE 表1 RENAME TO 表2;修改索引1234567891011121314# 添加主键索引ALTER TABLE 表名 ADD PRIMARY KEY (字段名)# 添加唯一索引ALTER TABLE 表名 ADD UNIQUE (字段名)# 添加普通索引ALTER TABLE 表名 ADD INDEX (字段名)# 添加全文索引ALTER TABLE 表名 ADD FULLTEXT (字段名)# 添加联合索引ALTER TABLE 表名 ADD INDEX 联合索引名 (字段1,字段2,字段3)]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>alter</tag>
        <tag>修改</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[那些年碰到的神级sql]]></title>
    <url>%2Fpost%2F%E9%82%A3%E4%BA%9B%E5%B9%B4%E7%A2%B0%E5%88%B0%E7%9A%84%E7%A5%9E%E7%BA%A7sql%2F</url>
    <content type="text"><![CDATA[计算两日期之间的工作日12345678910SELECT 5 * ( DATEDIFF('2016-10-31', '2016-10-01') DIV 7 ) + MID( '0123444401233334012222340111123400001234000123440', 7 * WEEKDAY('2016-10-01') + WEEKDAY('2016-10-31') + 1, 1 ) + 1 WorkingDaysFROM DUAL;最高效的删除重复记录的方法1DELETE FROM table1 a WHERE a.field > (SELECT MIN(b.field) FROM table2 b WHERE b.id = a.id);]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>神级</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql的时间日期类型]]></title>
    <url>%2Fpost%2Fmysql%E7%9A%84%E6%97%B6%E9%97%B4%E6%97%A5%E6%9C%9F%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[TIMESTAMP 把客户端插入的时间从当前时区转化为 UTC（世界标准时间）进行存储。查询时，将其又转化为客户端当前时区进行返回。而 DATETIME 不做任何改变，基本上是原样输入和输出。所以对于跨时区的业务，TIMESTAMP 更为合适。TIMESTAMP 比 DATETIME 存储时间范围要小得多。5.6 及之前版本只有 TIMESTAMP 支持默认初始化当前时间及自动更新，且一张表中只支持一个字段，到了 5.7 及之后版本 TIMESTAMP 和 DATETIME 都支持且没有数量限制。]]></content>
      <categories>
        <category>mysql</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>时间</tag>
        <tag>日期</tag>
        <tag>类型</tag>
      </tags>
  </entry>
</search>
